{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import random\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the sentiment analysis on the emotions dataset\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "with open('Emotions_dataset.csv') as file:\n",
    "    data = file.read().split('\\n')\n",
    "# Randomly select a journal entry\n",
    "line = data[random.randint(0, len(data))]\n",
    "print(line)\n",
    "line = line.split(',', 2)\n",
    "jnl_entry = line[2]\n",
    "sentiment = analyzer.polarity_scores(jnl_entry)\n",
    "print(sentiment['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the embedding model\n",
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embedding = emb_model.encode(jnl_entry)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating JSON objects from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data from the csv file.\n",
    "with open('Emotions_dataset.csv', 'r') as file:\n",
    "    data = file.read().split('\\n')\n",
    "# Removing the header from the data.\n",
    "data = data[1:]\n",
    "snt_analyzer = SentimentIntensityAnalyzer()\n",
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# Splitting the data into the respective columns and storing them in a list of dictionaries.\n",
    "entries = []\n",
    "for line in data:\n",
    "    line = line.split(',', 2)\n",
    "    if not (len(line) < 2):\n",
    "       jnl_entry = line[2]\n",
    "       # Getting the sentiment score of the journal entry.\n",
    "       sentiment = snt_analyzer.polarity_scores(jnl_entry)\n",
    "       # Embedding the journal entry.\n",
    "       embedding = emb_model.encode(jnl_entry)\n",
    "       entry = {\n",
    "           'id' : \"jnl_\" + line[0],\n",
    "           'emotion' : line[1],\n",
    "           'journal_entry' : line[2],\n",
    "           'sentiment_score' : sentiment['compound'],\n",
    "           'embedding' : embedding.tolist()\n",
    "       }\n",
    "       entries.append(entry)\n",
    "# Writing the data to a json file.\n",
    "with open('Emotions_dataset.json', 'w') as file:\n",
    "    file.write(json.dumps(entries, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the embedded data in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the vector data storage\n",
    "DIMENSIONS = 384\n",
    "# Creating an instance of the faiss index.\n",
    "index = faiss.IndexFlatL2(DIMENSIONS)\n",
    "with open('Emotions_dataset.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "line = data[0]\n",
    "embedding = line['embedding']\n",
    "index.add(np.array([embedding]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS = 384\n",
    "# Creating an instance of the faiss index.\n",
    "index = faiss.IndexFlatL2(DIMENSIONS)\n",
    "with open('Emotions_dataset.json', 'r') as file:\n",
    "    jnl_entries = json.load(file)\n",
    "embeddings = np.array([entry['embedding'] for entry in jnl_entries])\n",
    "index.add(embeddings)\n",
    "\n",
    "def search(query, index, emb_model, jnl_entries, k=10):\n",
    "    '''This function takes the user's query and returns the top k journal entries that are similar to the query.'''\n",
    "    query_embedding = np.array(emb_model.encode(query)).reshape(1, -1)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    results = [{'journal_entry':jnl_entries[i]['journal_entry'], 'emotion': jnl_entries[i]['emotion'], 'sentiment_score':jnl_entries[i]['sentiment_score']} for i in indices[0]]\n",
    "    return results, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Because ridiculously attractive people also have self esteem issues and depression Guess what honey The world sucks for everyone Thereâ€™s no escape We will all die in misery and alone\"\n",
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "search_results, distances  = search(user_query, index, emb_model, jnl_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the index and the retrieved context to generate information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_community tiktoken langchain-openai langchainhub langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the generation of the prompt\n",
    "# List of emotions to choose from\n",
    "EMOTIONAL_STATES = [\"Hopeful\", \"Anxious\", \"Inspired\", \"Overwhelmed\", \"Peaceful\", \"Frustrated\", \"Curious\", \"Uncertain\", \"Hopelessness\"]\n",
    "# Prompt template\n",
    "template = \"\"\"Give the most relevant emotion to the following journal entry based on the sentiment score and the mapped emotions from the given context.\n",
    "context: {context}\n",
    "journal entry: {journal_entry}\n",
    "Note: only choose from the following emotions and only output that emotion: {EMOTIONAL_STATES}\"\"\"\n",
    "# Add the template to the prompt\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "llm = ChatOpenAI(model_name = \"gpt-4o-mini\", temperature = 0)\n",
    "# Combining the prompt and the language model\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({'context': search_results, 'journal_entry': user_query, 'EMOTIONAL_STATES': EMOTIONAL_STATES})\n",
    "# Extracting the emotion from the full response\n",
    "emotion = response.content\n",
    "emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved version of prompt generation\n",
    "# TODO: find a way to provide the context to the model with out retrieving it separately\n",
    "# DIMENSIONS = 384\n",
    "# Creating an instance of the faiss index.\n",
    "# index = faiss.IndexFlatL2(DIMENSIONS)\n",
    "with open('Emotions_dataset.json', 'r') as file:\n",
    "    jnl_entries = json.load(file)\n",
    "documents = [Document(page_content=entry['journal_entry']) for entry in jnl_entries]\n",
    "# embeddings = np.array([entry['embedding'] for entry in jnl_entries])\n",
    "emb_model = HuggingFaceBgeEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "# index.add(embeddings)\n",
    "vector_store = FAISS.from_documents(documents=documents, embedding=emb_model)\n",
    "vector_store.save_local('emotions_vector_store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vectors = FAISS.load_local('emotions_vector_store', embeddings=emb_model, allow_dangerous_deserialization=True)\n",
    "retriever = loaded_vectors.as_retriever(k=10)\n",
    "llm = ChatOpenAI(model_name = \"gpt-4o-mini\", temperature = 0)\n",
    "rag_chain = (  \n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "rag_chain.invoke({'context': retriever, 'journal_entry': user_query, 'EMOTIONAL_STATES': EMOTIONAL_STATES})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only run the code above if absolutely necessary, and only do so selectively!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and preprocessing the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweet_emotions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['tweet_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['sentiment'] == 'empty'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['sentiment'] == 'empty'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = df['sentiment'].unique()\n",
    "for emotion in emotions:\n",
    "    print(emotion, end=': ')\n",
    "    count = df[df['sentiment'] == emotion].count().values[0]\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_fig = px.bar(\n",
    "    x=emotions,\n",
    "    y=[df[df['sentiment'] == emotion].count().values[0] for emotion in emotions],\n",
    "    labels={'x':'Emotion', 'y':'Count'},\n",
    "    title='Count of each emotion in the dataset',\n",
    "    width=700,\n",
    "    height=400\n",
    ")\n",
    "emotions_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['content'].str.contains('@')].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prov = df[~df['content'].str.contains('@')]\n",
    "df_prov.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prov.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prov.to_csv('tweet_emotions_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.read_csv('tweet_emotions_cleaned.csv')\n",
    "indices = np.arange(len(df_cleaned))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "train_df = df_cleaned.iloc[train_indices]\n",
    "test_df = df_cleaned.iloc[test_indices]\n",
    "train_df.to_csv('tweet_emotions_train.csv', index=False)\n",
    "test_df.to_csv('tweet_emotions_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_emotions_cleaned.csv', 'r') as file:\n",
    "    data = file.read().split('\\n')\n",
    "# Removing the header from the data.\n",
    "data = data[1:]\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_emotions_train.csv', 'r') as file:\n",
    "    data = file.read().split('\\n')\n",
    "# Removing the header from the data.\n",
    "data = data[1:]\n",
    "snt_analyzer = SentimentIntensityAnalyzer()\n",
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# Splitting the data into the respective columns and storing them in a list of dictionaries.\n",
    "entries = []\n",
    "for i, line in enumerate(data):\n",
    "    line = line.split(',', 1)\n",
    "    if not (len(line) < 2):\n",
    "       jnl_entry = line[1]\n",
    "       # Getting the sentiment score of the journal entry.\n",
    "       sentiment = snt_analyzer.polarity_scores(jnl_entry)\n",
    "       # Embedding the journal entry.\n",
    "       embedding = emb_model.encode(jnl_entry)\n",
    "       entry = {\n",
    "           'id' : \"jnl_\" + str(i),\n",
    "           'emotion' : line[0],\n",
    "           'journal_entry' : line[1],\n",
    "           'sentiment_score' : sentiment['compound'],\n",
    "           'embedding' : embedding.tolist()\n",
    "       }\n",
    "       entries.append(entry)\n",
    "# Writing the data to a json file.\n",
    "with open('Emotions_dataset_vader_am.json', 'w') as file:\n",
    "    file.write(json.dumps(entries, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cautious with code above here!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = pd.read_json('Emotions_dataset_vader_am.json')\n",
    "df_json.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion metrics -> histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json['journal_entry'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snt_neu = df_json[df_json['sentiment_score'] == 0]\n",
    "df_snt_neu['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snt_pos = df_json[df_json['sentiment_score'] > 0]\n",
    "df_snt_pos['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snt_pos.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    # Get model prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        scores = F.softmax(outputs.logits, dim=1) \n",
    "    # The model returns scores for 3 classes: negative (0), neutral (1), positive (2)\n",
    "    # We can calculate the sentiment by subtracting the negative score from the positive score\n",
    "    neg_score = float(scores[0][0])\n",
    "    neu_score = float(scores[0][1])\n",
    "    pos_score = float(scores[0][2])\n",
    "    raw_score = pos_score - neg_score\n",
    "    # Adjust for uncertainty\n",
    "    adjusted_score = raw_score * (1- neu_score)\n",
    "    return {\n",
    "        \"raw_score\": raw_score,\n",
    "        \"adjusted_score\": adjusted_score,\n",
    "        \"positive_score\": pos_score,\n",
    "        \"neutral_score\": neu_score,\n",
    "        \"negative_score\": neg_score\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "text = \"Layin n bed with a headache  ughhhh...waitin on your call...\"\n",
    "result = analyze_sentiment(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_emotions_train.csv', 'r') as file:\n",
    "    data = file.read().split('\\n')\n",
    "# Removing the header from the data.\n",
    "data = data[1:]\n",
    "# Setting up the sentiment analysis model\n",
    "snt_model = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(snt_model)\n",
    "snt_analyzer = AutoModelForSequenceClassification.from_pretrained(snt_model)\n",
    "# Setting up the embedding model\n",
    "emb_model = \"text-embedding-3-small\"\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    # Get model prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = snt_analyzer(**inputs)\n",
    "        scores = F.softmax(outputs.logits, dim=1) \n",
    "    # The model returns scores for 3 classes: negative (0), neutral (1), positive (2)\n",
    "    # We can calculate the sentiment by subtracting the negative score from the positive score\n",
    "    neg_score = float(scores[0][0])\n",
    "    neu_score = float(scores[0][1])\n",
    "    pos_score = float(scores[0][2])\n",
    "    raw_score = pos_score - neg_score\n",
    "    # Adjust for uncertainty\n",
    "    adjusted_score = raw_score * (1- neu_score)\n",
    "    return {\n",
    "        # Returning all the values for testing purposes, remove unnecessary values later\n",
    "        \"raw_score\": raw_score,\n",
    "        \"adjusted_score\": adjusted_score,\n",
    "        \"positive_score\": pos_score,\n",
    "        \"neutral_score\": neu_score,\n",
    "        \"negative_score\": neg_score\n",
    "    }\n",
    "\n",
    "# Splitting the data into the respective columns and storing them in a list of dictionaries.\n",
    "entries = []\n",
    "for i, line in enumerate(data):\n",
    "    line = line.split(',', 1)\n",
    "    if not (len(line) < 2):\n",
    "        jnl_entry = line[1]\n",
    "        # Getting the sentiment score of the journal entry.\n",
    "        results = analyze_sentiment(jnl_entry)\n",
    "        # Embedding the journal entry.\n",
    "        emb_response = openai.embeddings.create(\n",
    "            input=jnl_entry,\n",
    "            model=emb_model\n",
    "        )\n",
    "        embedding = emb_response.data[0].embedding\n",
    "        # Storing the data in a dictionary\n",
    "        entry = {\n",
    "            'id' : \"jnl_\" + str(i),\n",
    "            'emotion' : line[0],\n",
    "            'journal_entry' : line[1],\n",
    "            'sentiment_score' : results.get('adjusted_score'),\n",
    "            'embedding' : embedding\n",
    "        }\n",
    "        entries.append(entry)\n",
    "# Writing the data to a json file.\n",
    "with open('Emotions_dataset_cardiff_oai.json', 'w') as file:\n",
    "    file.write(json.dumps(entries, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cardiff = pd.read_json('Emotions_dataset_cardiff_oai.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>journal_entry</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jnl_1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>is installing the Iphone and Ipod touch sdk 2....</td>\n",
       "      <td>0.039998</td>\n",
       "      <td>[0.031230790540575003, -0.002684272127225, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jnl_3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I have to go to work now.</td>\n",
       "      <td>-0.259220</td>\n",
       "      <td>[-0.0018639501649880001, 0.037988256663084, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jnl_4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Salad from krogers...  I was hungry.</td>\n",
       "      <td>0.035736</td>\n",
       "      <td>[-0.052385926246643004, -0.029814580455422002,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jnl_12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Just work up</td>\n",
       "      <td>0.079786</td>\n",
       "      <td>[0.0074366098269820005, 0.021141819655895, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jnl_14</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I hate funerals.</td>\n",
       "      <td>-0.945050</td>\n",
       "      <td>[-0.005770623218268001, 0.003911630250513, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jnl_24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Miss Cauzinhoooo already</td>\n",
       "      <td>-0.188362</td>\n",
       "      <td>[0.046856377273797004, -0.0016631120815870002,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>jnl_26</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Same Difference Today  going to go and have a ...</td>\n",
       "      <td>0.150722</td>\n",
       "      <td>[-0.00887294486165, 0.006200557108968, -0.0235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>jnl_41</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NOT excited for 32 people reservation in the m...</td>\n",
       "      <td>0.155015</td>\n",
       "      <td>[0.023313973098993003, 0.025849299505352002, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>jnl_50</td>\n",
       "      <td>neutral</td>\n",
       "      <td>character designs complete! .... in about a we...</td>\n",
       "      <td>0.364673</td>\n",
       "      <td>[0.031505569815635, 0.012621497735381002, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>jnl_53</td>\n",
       "      <td>neutral</td>\n",
       "      <td>today is a busy day. exhausting!</td>\n",
       "      <td>-0.316422</td>\n",
       "      <td>[-0.005164267960935, 0.018428282812237, -0.047...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  emotion                                      journal_entry  \\\n",
       "1    jnl_1  neutral  is installing the Iphone and Ipod touch sdk 2....   \n",
       "3    jnl_3  neutral                          I have to go to work now.   \n",
       "4    jnl_4  neutral               Salad from krogers...  I was hungry.   \n",
       "12  jnl_12  neutral                                       Just work up   \n",
       "14  jnl_14  neutral                                   I hate funerals.   \n",
       "24  jnl_24  neutral                           Miss Cauzinhoooo already   \n",
       "26  jnl_26  neutral  Same Difference Today  going to go and have a ...   \n",
       "41  jnl_41  neutral  NOT excited for 32 people reservation in the m...   \n",
       "50  jnl_50  neutral  character designs complete! .... in about a we...   \n",
       "53  jnl_53  neutral                   today is a busy day. exhausting!   \n",
       "\n",
       "    sentiment_score                                          embedding  \n",
       "1          0.039998  [0.031230790540575003, -0.002684272127225, -0....  \n",
       "3         -0.259220  [-0.0018639501649880001, 0.037988256663084, -0...  \n",
       "4          0.035736  [-0.052385926246643004, -0.029814580455422002,...  \n",
       "12         0.079786  [0.0074366098269820005, 0.021141819655895, -0....  \n",
       "14        -0.945050  [-0.005770623218268001, 0.003911630250513, -0....  \n",
       "24        -0.188362  [0.046856377273797004, -0.0016631120815870002,...  \n",
       "26         0.150722  [-0.00887294486165, 0.006200557108968, -0.0235...  \n",
       "41         0.155015  [0.023313973098993003, 0.025849299505352002, -...  \n",
       "50         0.364673  [0.031505569815635, 0.012621497735381002, -0.0...  \n",
       "53        -0.316422  [-0.005164267960935, 0.018428282812237, -0.047...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cardiff[df_cardiff['emotion'] == 'neutral'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distil = pd.read_json(\"Emotions_dataset_distil_oai.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>journal_entry</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jnl_1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>is installing the Iphone and Ipod touch sdk 2....</td>\n",
       "      <td>-0.510728</td>\n",
       "      <td>[0.031205531209707003, -0.002723266137763, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jnl_3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I have to go to work now.</td>\n",
       "      <td>-0.991278</td>\n",
       "      <td>[-0.0018639501649880001, 0.037988256663084, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jnl_4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Salad from krogers...  I was hungry.</td>\n",
       "      <td>-0.986555</td>\n",
       "      <td>[-0.052385926246643004, -0.029814580455422002,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jnl_12</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Just work up</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>[0.0074681695550680004, 0.021164717152714, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jnl_14</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I hate funerals.</td>\n",
       "      <td>-0.993923</td>\n",
       "      <td>[-0.005717813502997, 0.0039062288124110003, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jnl_24</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Miss Cauzinhoooo already</td>\n",
       "      <td>-0.979553</td>\n",
       "      <td>[0.046856377273797004, -0.0016631120815870002,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>jnl_26</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Same Difference Today  going to go and have a ...</td>\n",
       "      <td>0.473131</td>\n",
       "      <td>[-0.00887294486165, 0.006200557108968, -0.0235...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>jnl_41</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NOT excited for 32 people reservation in the m...</td>\n",
       "      <td>-0.994857</td>\n",
       "      <td>[0.023314835503697003, 0.025850255042314002, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>jnl_50</td>\n",
       "      <td>neutral</td>\n",
       "      <td>character designs complete! .... in about a we...</td>\n",
       "      <td>-0.440690</td>\n",
       "      <td>[0.031540501862764005, 0.012770409695804001, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>jnl_53</td>\n",
       "      <td>neutral</td>\n",
       "      <td>today is a busy day. exhausting!</td>\n",
       "      <td>-0.998356</td>\n",
       "      <td>[-0.005177229642868, 0.018358102068305, -0.047...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  emotion                                      journal_entry  \\\n",
       "1    jnl_1  neutral  is installing the Iphone and Ipod touch sdk 2....   \n",
       "3    jnl_3  neutral                          I have to go to work now.   \n",
       "4    jnl_4  neutral               Salad from krogers...  I was hungry.   \n",
       "12  jnl_12  neutral                                       Just work up   \n",
       "14  jnl_14  neutral                                   I hate funerals.   \n",
       "24  jnl_24  neutral                           Miss Cauzinhoooo already   \n",
       "26  jnl_26  neutral  Same Difference Today  going to go and have a ...   \n",
       "41  jnl_41  neutral  NOT excited for 32 people reservation in the m...   \n",
       "50  jnl_50  neutral  character designs complete! .... in about a we...   \n",
       "53  jnl_53  neutral                   today is a busy day. exhausting!   \n",
       "\n",
       "    sentiment_score                                          embedding  \n",
       "1         -0.510728  [0.031205531209707003, -0.002723266137763, -0....  \n",
       "3         -0.991278  [-0.0018639501649880001, 0.037988256663084, -0...  \n",
       "4         -0.986555  [-0.052385926246643004, -0.029814580455422002,...  \n",
       "12         0.999224  [0.0074681695550680004, 0.021164717152714, -0....  \n",
       "14        -0.993923  [-0.005717813502997, 0.0039062288124110003, -0...  \n",
       "24        -0.979553  [0.046856377273797004, -0.0016631120815870002,...  \n",
       "26         0.473131  [-0.00887294486165, 0.006200557108968, -0.0235...  \n",
       "41        -0.994857  [0.023314835503697003, 0.025850255042314002, -...  \n",
       "50        -0.440690  [0.031540501862764005, 0.012770409695804001, -...  \n",
       "53        -0.998356  [-0.005177229642868, 0.018358102068305, -0.047...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_distil[df_distil['emotion'] == 'neutral'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

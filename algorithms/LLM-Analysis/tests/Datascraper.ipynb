{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import random\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the sentiment analysis on the emotions dataset\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "with open('Emotions_dataset.csv') as file:\n",
    "    data = file.read().split('\\n')\n",
    "# Randomly select a journal entry\n",
    "line = data[random.randint(0, len(data))]\n",
    "print(line)\n",
    "line = line.split(',', 2)\n",
    "jnl_entry = line[2]\n",
    "sentiment = analyzer.polarity_scores(jnl_entry)\n",
    "print(sentiment['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the embedding model\n",
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embedding = emb_model.encode(jnl_entry)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating JSON objects from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data from the csv file.\n",
    "with open('Emotions_dataset.csv', 'r') as file:\n",
    "    data = file.read().split('\\n')\n",
    "# Removing the header from the data.\n",
    "data = data[1:]\n",
    "snt_analyzer = SentimentIntensityAnalyzer()\n",
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# Splitting the data into the respective columns and storing them in a list of dictionaries.\n",
    "entries = []\n",
    "for line in data:\n",
    "    line = line.split(',', 2)\n",
    "    if not (len(line) < 2):\n",
    "       jnl_entry = line[2]\n",
    "       # Getting the sentiment score of the journal entry.\n",
    "       sentiment = snt_analyzer.polarity_scores(jnl_entry)\n",
    "       # Embedding the journal entry.\n",
    "       embedding = emb_model.encode(jnl_entry)\n",
    "       entry = {\n",
    "           'id' : \"jnl_\" + line[0],\n",
    "           'emotion' : line[1],\n",
    "           'journal_entry' : line[2],\n",
    "           'sentiment_score' : sentiment['compound'],\n",
    "           'embedding' : embedding.tolist()\n",
    "       }\n",
    "       entries.append(entry)\n",
    "# Writing the data to a json file.\n",
    "with open('Emotions_dataset.json', 'w') as file:\n",
    "    file.write(json.dumps(entries, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the embedded data in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the vector data storage\n",
    "DIMENSIONS = 384\n",
    "# Creating an instance of the faiss index.\n",
    "index = faiss.IndexFlatL2(DIMENSIONS)\n",
    "with open('Emotions_dataset.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "line = data[0]\n",
    "embedding = line['embedding']\n",
    "index.add(np.array([embedding]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS = 384\n",
    "# Creating an instance of the faiss index.\n",
    "index = faiss.IndexFlatL2(DIMENSIONS)\n",
    "with open('Emotions_dataset.json', 'r') as file:\n",
    "    jnl_entries = json.load(file)\n",
    "embeddings = np.array([entry['embedding'] for entry in jnl_entries])\n",
    "index.add(embeddings)\n",
    "def search(query, index, emb_model, jnl_entries, k=10):\n",
    "    '''This function takes the user's query and returns the top k journal entries that are similar to the query.'''\n",
    "    query_embedding = np.array(emb_model.encode(query)).reshape(1, -1)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    results = [{'journal_entry':jnl_entries[i]['journal_entry'], 'emotion': jnl_entries[i]['emotion'], 'sentiment_score':jnl_entries[i]['sentiment_score']} for i in indices[0]]\n",
    "    return results, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Because ridiculously attractive people also have self esteem issues and depression Guess what honey The world sucks for everyone Thereâ€™s no escape We will all die in misery and alone\"\n",
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "search_results, distances  = search(user_query, index, emb_model, jnl_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the index and the retrieved context to generate information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.16-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (2.0.30)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.11.12-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.32 (from langchain_community)\n",
      "  Downloading langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain_community)\n",
      "  Downloading langsmith-0.3.6-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Collecting openai<2.0.0,>=1.58.1 (from langchain-openai)\n",
      "  Downloading openai-1.61.1-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchainhub) (23.2)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.32->langchain_community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain_community)\n",
      "  Downloading orjson-3.10.15-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain_community)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain_community)\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.0.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain_community) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain_community) (2.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.58.1->langchain-openai) (0.4.6)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.16-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.8/2.5 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.3/2.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.4/2.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 2.5 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.5 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 524.3/884.5 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 884.5/884.5 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading langchain_openai-0.3.4-py3-none-any.whl (54 kB)\n",
      "Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
      "Downloading langchain-0.3.17-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.11.12-cp311-cp311-win_amd64.whl (442 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
      "Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.3.6-py3-none-any.whl (332 kB)\n",
      "Downloading openai-1.61.1-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.15-cp311-cp311-win_amd64.whl (133 kB)\n",
      "Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "Downloading zstandard-0.23.0-cp311-cp311-win_amd64.whl (495 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: zstandard, types-requests, tenacity, python-dotenv, propcache, orjson, mypy-extensions, multidict, marshmallow, jsonpatch, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, tiktoken, requests-toolbelt, langchainhub, aiosignal, pydantic-settings, openai, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain_community\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.57.4\n",
      "    Uninstalling openai-1.57.4:\n",
      "      Successfully uninstalled openai-1.57.4\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.12 aiosignal-1.3.2 dataclasses-json-0.6.7 frozenlist-1.5.0 httpx-sse-0.4.0 jsonpatch-1.33 langchain-0.3.17 langchain-core-0.3.34 langchain-openai-0.3.4 langchain-text-splitters-0.3.6 langchain_community-0.3.16 langchainhub-0.1.21 langsmith-0.3.6 marshmallow-3.26.1 multidict-6.1.0 mypy-extensions-1.0.0 openai-1.61.1 orjson-3.10.15 propcache-0.2.1 pydantic-settings-2.7.1 python-dotenv-1.0.1 requests-toolbelt-1.0.0 tenacity-9.0.0 tiktoken-0.8.0 types-requests-2.32.0.20241016 typing-inspect-0.9.0 yarl-1.18.3 zstandard-0.23.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community tiktoken langchain-openai langchainhub langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_core in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.34)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_core) (0.3.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_core) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_core) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_core) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_core) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_core) (2.10.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain_core) (2.27.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (4.0.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain_core) (2.0.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\dinit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_core) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most relevant emotion for the given journal entry is **Hopelessness**. The tone of the entry expresses a bleak outlook on life and relationships, indicating a sense of despair and resignation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hopelessness'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the generation of the prompt\n",
    "# List of emotions to choose from\n",
    "EMOTIONAL_STATES = [\"Hopeful\", \"Anxious\", \"Inspired\", \"Overwhelmed\", \"Peaceful\", \"Frustrated\", \"Curious\", \"Uncertain\", \"Hopelessness\"]\n",
    "# Prompt template\n",
    "template = \"\"\"Give the most relevant emotion to the following journal entry based on the sentiment score and the mapped emotions from the given context.\n",
    "context: {context}\n",
    "journal entry: {journal_entry}\n",
    "Note: only choose from the following emotions: {EMOTIONAL_STATES}\"\"\"\n",
    "# Add the template to the prompt\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "llm = ChatOpenAI(model_name = \"gpt-4o-mini\", temperature = 0)\n",
    "# Combining the prompt and the language model\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({'context': search_results, 'journal_entry': user_query, 'EMOTIONAL_STATES': EMOTIONAL_STATES})\n",
    "# Extracting the emotion from the full response\n",
    "emotion = response.content.split(\"**\", 2)[1]\n",
    "emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved version of prompt generation\n",
    "# TODO: find a way to provide the context to the model with out retrieving it separately"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

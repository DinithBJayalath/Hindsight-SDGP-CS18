{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mining the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import random\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the sentiment analysis on the emotions dataset\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "with open('Emotions_dataset.csv') as file:\n",
    "    data = file.read().split('\\n')\n",
    "# Randomly select a journal entry\n",
    "line = data[random.randint(0, len(data))]\n",
    "print(line)\n",
    "line = line.split(',', 2)\n",
    "jnl_entry = line[2]\n",
    "sentiment = analyzer.polarity_scores(jnl_entry)\n",
    "print(sentiment['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the embedding model\n",
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embedding = emb_model.encode(jnl_entry)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating JSON objects from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data from the csv file.\n",
    "with open('Emotions_dataset.csv', 'r') as file:\n",
    "    data = file.read().split('\\n')\n",
    "# Removing the header from the data.\n",
    "data = data[1:]\n",
    "snt_analyzer = SentimentIntensityAnalyzer()\n",
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# Splitting the data into the respective columns and storing them in a list of dictionaries.\n",
    "entries = []\n",
    "for line in data:\n",
    "    line = line.split(',', 2)\n",
    "    if not (len(line) < 2):\n",
    "       jnl_entry = line[2]\n",
    "       # Getting the sentiment score of the journal entry.\n",
    "       sentiment = snt_analyzer.polarity_scores(jnl_entry)\n",
    "       # Embedding the journal entry.\n",
    "       embedding = emb_model.encode(jnl_entry)\n",
    "       entry = {\n",
    "           'id' : \"jnl_\" + line[0],\n",
    "           'emotion' : line[1],\n",
    "           'journal_entry' : line[2],\n",
    "           'sentiment_score' : sentiment['compound'],\n",
    "           'embedding' : embedding.tolist()\n",
    "       }\n",
    "       entries.append(entry)\n",
    "# Writing the data to a json file.\n",
    "with open('Emotions_dataset.json', 'w') as file:\n",
    "    file.write(json.dumps(entries, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the embedded data in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the vector data storage\n",
    "DIMENSIONS = 384\n",
    "# Creating an instance of the faiss index.\n",
    "index = faiss.IndexFlatL2(DIMENSIONS)\n",
    "with open('Emotions_dataset.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "line = data[0]\n",
    "embedding = line['embedding']\n",
    "index.add(np.array([embedding]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS = 384\n",
    "# Creating an instance of the faiss index.\n",
    "index = faiss.IndexFlatL2(DIMENSIONS)\n",
    "with open('Emotions_dataset.json', 'r') as file:\n",
    "    jnl_entries = json.load(file)\n",
    "embeddings = np.array([entry['embedding'] for entry in jnl_entries])\n",
    "index.add(embeddings)\n",
    "def search(query, index, emb_model, jnl_entries, k=10):\n",
    "    '''This function takes the user's query and returns the top k journal entries that are similar to the query.'''\n",
    "    query_embedding = np.array(emb_model.encode(query)).reshape(1, -1)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    results = [{'journal_entry':jnl_entries[i]['journal_entry'], 'emotion': jnl_entries[i]['emotion']} for i in indices[0]]\n",
    "    return results, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwhelmed\n",
      "Anxious\n",
      "Inspired\n",
      "Hopeful\n",
      "Frustrated\n",
      "Peaceful\n",
      "Frustrated\n",
      "Frustrated\n",
      "Frustrated\n",
      "Frustrated\n"
     ]
    }
   ],
   "source": [
    "user_query = \"I'm feeling really stressed with my workload.\"\n",
    "emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "search_results, distances  = search(user_query, index, emb_model, jnl_entries)\n",
    "for result in search_results:\n",
    "    print(result['emotion'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
